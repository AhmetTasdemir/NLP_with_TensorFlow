{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe: Global Vectors for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pylab\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "\n",
    "### Downloading the data\n",
    "\n",
    "This code downloads a [BBC dataset](hhttp://mlg.ucd.ie/files/datasets/bbc-fulltext.zip) consisting of news articles published by BBC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file...\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "\n",
    "\n",
    "def download_data(url, data_dir):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    \n",
    "    # Create the data directory if not exist\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "    \n",
    "    # If file doesnt exist, download\n",
    "    if not os.path.exists(file_path):\n",
    "        print('Downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print(\"File already exists\")\n",
    "  \n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    \n",
    "    # If data has not been extracted already, extract data\n",
    "    if not os.path.exists(extract_path):        \n",
    "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "    else:\n",
    "        print(\"bbc-fulltext.zip has already been extracted\")\n",
    "    \n",
    "download_data(url, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data without Preprocessing \n",
    "\n",
    "Here we read all the files and keep them as a list of strings, where each string is a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 361.txt\n",
      "Detected 2225 stories\n",
      "865163 words found in the total news set\n",
      "Example words (start):  Windows worm travels with Tetris  Users are being \n",
      "Example words (end):  is years at Stradey as \"the best time of my life.\"\n"
     ]
    }
   ],
   "source": [
    "def read_data(data_dir):\n",
    "    \n",
    "    # This will contain the full list of stories\n",
    "    news_stories = []\n",
    "    \n",
    "    print(\"Reading files\")\n",
    "    \n",
    "    i = 0 # Just used for printing progress\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        \n",
    "        for fi, f in enumerate(files):\n",
    "            \n",
    "            # We don't read the readme file\n",
    "            if 'README' in f:\n",
    "                continue\n",
    "            \n",
    "            # Printing progress\n",
    "            i += 1\n",
    "            print(\".\"*i, f, end='\\r')\n",
    "            \n",
    "            # Open the file\n",
    "            with open(os.path.join(root, f), encoding='latin-1') as f:\n",
    "                \n",
    "                story = []\n",
    "                # Read all the lines\n",
    "                for row in f:\n",
    "                                        \n",
    "                    story.append(row.strip())\n",
    "                    \n",
    "                # Create a single string with all the rows in the doc\n",
    "                story = ' '.join(story)                        \n",
    "                # Add that to the list\n",
    "                news_stories.append(story)  \n",
    "                \n",
    "        print('', end='\\r')\n",
    "        \n",
    "    print(\"\\nDetected {} stories\".format(len(news_stories)))\n",
    "    return news_stories\n",
    "                \n",
    "  \n",
    "news_stories = read_data(os.path.join('data', 'bbc'))\n",
    "\n",
    "# Printing some stats and sample data\n",
    "print('{} words found in the total news set'.format(sum([len(story.split(' ')) for story in news_stories])))\n",
    "print('Example words (start): ',news_stories[0][:50])\n",
    "print('Example words (end): ',news_stories[-1][-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Tokenizer\n",
    "\n",
    "Here we build a tokenizer, that performs simple preprocessing like,\n",
    "\n",
    "* Converting letters to lower case\n",
    "* Removing punctuation\n",
    "\n",
    "and tokenize the strings based on a defined separator. Then each token is converted to an Integer ID, as computers understand numbers, not strings. In the background, the tokenizer builds a word to index dictionary, that defines a unique ID for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fitted on the tokenizer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "n_vocab = 15000 + 1\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=n_vocab - 1,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', oov_token=''\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(news_stories)\n",
    "print(\"Data fitted on the tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the word co-occurrence matrix\n",
    "\n",
    "Why GloVe shine above context window based method is that it employs global statistics of the corpus in to the model (according to authors). This is done by using information from the word co-occurance matrix to optimize the word vectors. Basically, the $X(i,j)$ entry of the co-occurance matrix says how frequent word $i$ to appear near $j$. \n",
    "\n",
    "We also use an optional weighting mechanishm to give more weight to words close together than to the ones further-apart (from experiments section of the paper).\n",
    "\n",
    "**Note**: When generating the matrix for the first time, it will take a significant amount of time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 2225/2225\n",
      "\n",
      "It took 479.4639596939087 seconds to generate the co-occurrence matrix\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import save_npz, load_npz\n",
    "\n",
    "def generate_cooc_matrix(text, tokenizer, window_size, n_vocab, use_weighting=True):\n",
    "    \n",
    "    # Convert list of text to list of list of word IDs\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    \n",
    "    # A sparse matrix to retain co-occurrences of words\n",
    "    cooc_mat = lil_matrix((n_vocab, n_vocab), dtype=np.float32)\n",
    "    \n",
    "    # Go through each sequence one by one\n",
    "    for si, sequence in enumerate(sequences):\n",
    "        \n",
    "        # Printing the progress\n",
    "        print('.'*(si+1), '{}/{}'.format(si+1, len(sequences)), end='\\r')\n",
    "        \n",
    "        # For each target word,\n",
    "        for i, wi in zip(np.arange(window_size, len(sequence)-window_size), sequence[window_size:-window_size]):\n",
    "            \n",
    "            # Get the context window word IDs\n",
    "            context_window = sequence[i-window_size: i+window_size+1]            \n",
    "            \n",
    "            # The weight for the words in the context window (except target word) will be 1\n",
    "            window_weights = np.ones(shape=(window_size*2 + 1,), dtype=np.float32)\n",
    "            window_weights[window_size] = 0.0\n",
    "\n",
    "            if use_weighting:\n",
    "                # If weighting is used, penalize context words based on distance to target word\n",
    "                distances = np.abs(np.arange(-window_size, window_size+1))\n",
    "                distances[window_size] = 1.0\n",
    "                # Update the sparse matrix\n",
    "                cooc_mat[wi, context_window] += window_weights/distances\n",
    "            else:\n",
    "                # Update the sparse matrix\n",
    "                cooc_mat[wi, context_window] += window_weights\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return cooc_mat    \n",
    "\n",
    "\n",
    "# Set this true or false, depending on whether you want to generate the matrix or reuse the existing\n",
    "generate_cooc = True\n",
    "\n",
    "# Generate the matrix\n",
    "if generate_cooc:\n",
    "    t1 = time.time()\n",
    "    cooc_mat = generate_cooc_matrix(news_stories, tokenizer, 1, n_vocab, True)\n",
    "    t2 = time.time()\n",
    "    print(\"It took {} seconds to generate the co-occurrence matrix\".format(t2-t1))\n",
    "    \n",
    "    save_npz(os.path.join('data','cooc_mat.npz'), cooc_mat.tocsr())\n",
    "# Load the matrix from disk\n",
    "else:\n",
    "    try:\n",
    "        cooc_mat = load_npz(os.path.join('data','cooc_mat.npz')).tolil()\n",
    "        print('Cooc matrix of type {} was loaded from disk'.format(type(cooc_mat).__name__))\n",
    "    except FileNotFoundError as ex:\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find the co-occurrence matrix on the disk. Did you generate the matrix by setting generate_cooc=True?\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the validity of the co-occurrence matrix\n",
    "\n",
    "Here we will see if the context around a given word has sensible words appearing in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fd3c094bc18>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3c094bbe0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3c1322ef0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3b9488160>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3b94885c0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3b9488908>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3b9488da0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3b9484278>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3b9484710>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3b9484ba8>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f90f0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f9518>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f99b0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f9e48>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f9390>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3b94841d0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f4208>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f4668>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f4b00>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f4e80>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8d0470>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8d0908>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8d0da0>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8d0c18>,\n",
       "  <matplotlib.axis.XTick at 0x7fd3bb8f4c50>],\n",
       " [Text(0, 0, 'she'),\n",
       "  Text(0, 0, 'such'),\n",
       "  Text(0, 0, 'pundit'),\n",
       "  Text(0, 0, 'he'),\n",
       "  Text(0, 0, 'it'),\n",
       "  Text(0, 0, 'said'),\n",
       "  Text(0, 0, 'i'),\n",
       "  Text(0, 0, 'cas'),\n",
       "  Text(0, 0, 'understands'),\n",
       "  Text(0, 0, 'we'),\n",
       "  Text(0, 0, 'website'),\n",
       "  Text(0, 0, 'a'),\n",
       "  Text(0, 0, 'is'),\n",
       "  Text(0, 0, \"it's\"),\n",
       "  Text(0, 0, 'on'),\n",
       "  Text(0, 0, 'wales'),\n",
       "  Text(0, 0, 'school'),\n",
       "  Text(0, 0, 'that'),\n",
       "  Text(0, 0, 'of'),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, 'in'),\n",
       "  Text(0, 0, 'and'),\n",
       "  Text(0, 0, 'for'),\n",
       "  Text(0, 0, 'the'),\n",
       "  Text(0, 0, 'bbc')])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "word = 'sport'\n",
    "assert word in tokenizer.word_index, 'Word {} is not in the tokenizer'.format(word)\n",
    "assert tokenizer.word_index[word] <= n_vocab, 'The word {} is an out of vocabuary word. Please try something else'.format(word)\n",
    "\n",
    "# Get the vector of co-occurrences for a given word \n",
    "cooc_vec = np.array(cooc_mat.getrow(tokenizer.word_index[word]).todense()).ravel()\n",
    "# Get indices of words with maximum value\n",
    "max_ind = np.argsort(cooc_vec)[-25:]\n",
    "\n",
    "# Plot the words and values\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(np.arange(0, 25), cooc_vec[max_ind])\n",
    "plt.xticks(ticks=np.arange(0, 25), labels=[tokenizer.index_word[i] for i in max_ind], rotation=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Defining Hyperparameters\n",
    "\n",
    "Here we define several hyperparameters including `batch_size` (amount of samples in a single batch) `embedding_size` (size of embedding vectors) `window_size` (context window size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512 # Data points in a single batch\n",
    "\n",
    "embedding_size = 128 # Dimension of the embedding vector.\n",
    "\n",
    "window_size=1 # We use a window size of 1 on either side of target word\n",
    "\n",
    "epochs = 5 # Number of epochs to train for\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors\n",
    "valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "# We sample valid datapoints randomly from a large window without always being deterministic\n",
    "valid_window = 250\n",
    "\n",
    "# When selecting valid examples, we select some of the most frequent words as well as\n",
    "# some moderately rare words as well\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)\n",
    "\n",
    "valid_term_ids = np.array(random.sample(range(valid_window), valid_size))\n",
    "valid_term_ids = np.append(\n",
    "    valid_term_ids, random.sample(range(1000, 1000+valid_window), valid_size),\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model Computations\n",
    "\n",
    "The model takes two inputs,\n",
    "\n",
    "* A (batch of) context word ID(s) - $i$\n",
    "* A (batch of) target word ID(s) - $j$\n",
    "\n",
    "and computes the following output,\n",
    "\n",
    "$w_i.\\tilde{w}_j + b_i + \\tilde{b}_j$\n",
    "\n",
    "where, $w_i$ is the context embeddings for the words in $i$, $\\tilde{w}_j$ is target embeddings for the words in $j$, $b_i$ and $\\tilde{b}_j$ are two separate biases for context and target spaces. Then the following loss function is used,\n",
    "\n",
    "$J = f(X_{ij}) \\sum_{i,j=1}^{V} (w_i\\tilde{w}_j + b_i + \\tilde{b}_j - log(X_{ij})^2$\n",
    "\n",
    "Here, X_{ij} is the value at (i,j) position in the co-occurrence matrix and f(X_{ij}) is a simple weighting function of X_{ij}. You can see that the loss function looks of the format,\n",
    "\n",
    "$J = A ( B - C ) ^ 2 $\n",
    "\n",
    "Therefore, we will use the mean-squared-error loss and feed in $f(X_{ij})$ values as sample weights during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"glove_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "target_embedding (Embedding)    (None, 128)          4142336     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "context_embedding (Embedding)   (None, 128)          4142336     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           target_embedding[0][0]           \n",
      "                                                                 context_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "target_embedding_bias (Embeddin (None, 1)            32362       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "context_embedding_bias (Embeddi (None, 1)            32362       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1)            0           dot[0][0]                        \n",
      "                                                                 target_embedding_bias[0][0]      \n",
      "                                                                 context_embedding_bias[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 8,349,396\n",
      "Trainable params: 8,349,396\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Define two input layers for context and target words\n",
    "word_i = Input(shape=())\n",
    "word_j = Input(shape=())\n",
    "\n",
    "# Each context and target has their own embeddings (weights and biases)\n",
    "\n",
    "# Embedding weights\n",
    "embeddings_i = Embedding(n_vocab, embedding_size, name='target_embedding')(word_i)\n",
    "embeddings_j = Embedding(n_vocab, embedding_size, name='context_embedding')(word_j)\n",
    "\n",
    "# Embedding biases\n",
    "b_i = Embedding(n_vocab, 1, name='target_embedding_bias')(word_i)    \n",
    "b_j = Embedding(n_vocab, 1, name='context_embedding_bias')(word_j)\n",
    "\n",
    "# Compute the dot product between embedding vectors (i.e. w_i.w_j)\n",
    "ij_dot = Dot(axes=-1)([embeddings_i,embeddings_j])\n",
    "\n",
    "# Add the biases (i.e. w_i.w_j + b_i + b_j )\n",
    "pred = Add()([ij_dot, b_i, b_j])\n",
    "\n",
    "# The final model\n",
    "glove_model = Model(inputs=[word_i, word_j],outputs=pred, name='glove_model')\n",
    "\n",
    "# Glove has a specific loss function with a sound mathematical underpinning\n",
    "# It is a form of mean squared error\n",
    "glove_model.compile(loss=\"mse\", optimizer = 'adam')\n",
    "\n",
    "glove_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for GloVe model\n",
    "\n",
    "The Glove model we implemented, \n",
    "\n",
    "* Takes two inputs; context words and target words \n",
    "* Computes the mean squared error as, $(\\hat{y}_{ij} - log(X_{ij}))^2$ for the model output $\\hat{y}_{ij}$\n",
    "* Use sample weights returned by $f(X_{ij})$\n",
    "\n",
    "Therefore, in the data generator we return a tuple of,\n",
    "\n",
    "`(inputs, targets, sample weights)`\n",
    "\n",
    "which translates to,\n",
    "\n",
    "`((batch of target words, batch or context words), batch of log(X_{ij}), batch of f(X_{ij})`                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sequences = tokenizer.texts_to_sequences(news_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1792, 3193, 3842, 1908, 1521, 1398, 3949, 4283, 1398,    7]), array([ 131, 8370, 2335, 1680, 1198,  970, 8049, 3862,    7,    1]))\n",
      "[1.3862944 1.0986123 0.        0.6931472 0.        0.        0.6931472\n",
      " 0.        1.0986123 7.0184016]\n",
      "[0.08944272 0.07208434 0.03162277 0.05318296 0.03162277 0.03162277\n",
      " 0.05318296 0.03162277 0.07208434 1.        ]\n"
     ]
    }
   ],
   "source": [
    "def glove_data_generator(\n",
    "    sequences, window_size, batch_size, vocab_size, cooccurrence_matrix, x_max=100.0, alpha=0.75, seed=None\n",
    "):\n",
    "    \"\"\" Generate batches of inputs and targets for GloVe \"\"\"\n",
    "    \n",
    "    # Shuffle the data so that, every epoch, the order of data is different\n",
    "    rand_sequence_ids = np.arange(len(sequences))                    \n",
    "    np.random.shuffle(rand_sequence_ids)\n",
    "\n",
    "    # We will use a sampling table to make sure, we don't oversample stopwords\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "    \n",
    "    # For each story/article\n",
    "    for si in rand_sequence_ids:\n",
    "        \n",
    "        # Generate positive skip-grams while using sub-sampling \n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequences[si], \n",
    "            vocabulary_size=vocab_size, \n",
    "            window_size=window_size, \n",
    "            negative_samples=0.0, \n",
    "            shuffle=False,   \n",
    "            sampling_table=sampling_table,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        # Take targets and context words separately\n",
    "        targets, context = zip(*positive_skip_grams)\n",
    "        targets, context = np.array(targets).ravel(), np.array(context).ravel()\n",
    "        \n",
    "        \n",
    "        x_ij = np.array(cooccurrence_matrix[targets, context].toarray()).ravel()\n",
    "        \n",
    "        # Compute log - Introducing an additive shift to make sure we don't compute log(0)\n",
    "        log_x_ij = np.log(x_ij + 1)\n",
    "        \n",
    "        # Sample weights \n",
    "        # if x < x_max => (x/x_max)**alpha / else => 1        \n",
    "        sample_weights = np.where(x_ij < x_max, (x_ij/x_max)**alpha, 1)\n",
    "        \n",
    "        # If seed is not provided generate a random one\n",
    "        if not seed:\n",
    "            seed = random.randint(0, 10e6)\n",
    "        \n",
    "        # Shuffle data\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(context)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(targets)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(log_x_ij)\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(sample_weights)\n",
    "        \n",
    "        # Generate a batch or data in the format \n",
    "        # ((target words, context words), log(X_ij) <- true targets, f(X_ij) <- sample weights)\n",
    "        for eg_id_start in range(0, context.shape[0], batch_size):            \n",
    "            yield (\n",
    "                targets[eg_id_start: min(eg_id_start+batch_size, targets.shape[0])], \n",
    "                context[eg_id_start: min(eg_id_start+batch_size, context.shape[0])]\n",
    "            ), log_x_ij[eg_id_start: min(eg_id_start+batch_size, x_ij.shape[0])], \\\n",
    "            sample_weights[eg_id_start: min(eg_id_start+batch_size, sample_weights.shape[0])]\n",
    "\n",
    "\n",
    "# Generate some data\n",
    "news_glove_data_gen = glove_data_generator(\n",
    "    news_sequences, 2, 10, n_vocab\n",
    ")\n",
    "\n",
    "for x, y, z in news_glove_data_gen:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Here we train the GloVe model we defined above. We train for `epochs` and at the end of each epoch, we compute word similarities on a set of chosen validation words (`valid_term_ids`). Similar to in Chapter 3, we use a Keras callback to compute the most similar words.\n",
    "\n",
    "### Calculating Word Similarities\n",
    "\n",
    "We calculate the similarity between two given words in terms of the cosine distance. To do this efficiently we use matrix operations to do so, as shown below. Furthermore, we define the computations as a callback, which will automatically run at the end of an epoch during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_term_ids, model_with_embeddings, tokenizer):\n",
    "        \n",
    "        self.valid_term_ids = valid_term_ids\n",
    "        self.model_with_embeddings = model_with_embeddings\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\" Validation logic \"\"\"\n",
    "                \n",
    "        # We will use context embeddings to get the most similar words\n",
    "        # Other strategies include: using target embeddings, mean embeddings after avaraging context/target\n",
    "        embedding_weights = self.model_with_embeddings.get_layer(\"context_embedding\").get_weights()[0]\n",
    "        normalized_embeddings = embedding_weights / np.sqrt(np.sum(embedding_weights**2, axis=1, keepdims=True))\n",
    "        \n",
    "        # Get the embeddings corresponding to valid_term_ids\n",
    "        valid_embeddings = normalized_embeddings[self.valid_term_ids, :]\n",
    "        \n",
    "        # Compute the similarity between valid_term_ids and all the embeddings\n",
    "        # V x d (d x D) => V x D\n",
    "        top_k = 5 # Top k items will be displayed\n",
    "        similarity = np.dot(valid_embeddings, normalized_embeddings.T)\n",
    "        \n",
    "        # Invert similarity matrix to negative\n",
    "        # Ignore the first one because that would be the same word as the probe word\n",
    "        similarity_top_k = np.argsort(-similarity, axis=1)[:, 1: top_k+1]\n",
    "                \n",
    "        # Print the output\n",
    "        for i, term_id in enumerate(valid_term_ids):\n",
    "            \n",
    "            similar_word_str = ', '.join([self.tokenizer.index_word[j] for j in similarity_top_k[i, :] if j > 1])\n",
    "            print(\"{}: {}\".format(self.tokenizer.index_word[term_id], similar_word_str))\n",
    "        \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 started\n",
      "2241/2241 [==============================] - 93s 42ms/step - loss: 0.1051\n",
      "election: attorney, forthcoming, motors, grants, empt\n",
      "months: years, nations, thirds, electro, creativity\n",
      "with: honoured, dotted, entries, wham, mccormack\n",
      "you: i, we, they, care, don't\n",
      "were: are, want, where, know, can\n",
      "win: illness, who, lot, spaniard, shipped\n",
      "those: people, stooge, nas, is, much\n",
      "music: cameras, beta, mp3, modest, distribute\n",
      "also: who, which, be, we, backgrounds\n",
      "around: document, lectures, scams, themselves, plus\n",
      "best: supporting, actor, formula, asante, category\n",
      "him: used, also, selected, ira, plenty\n",
      "too: so, faster, how, frankly, less\n",
      "into: nintendo, been, us, it's, favourites\n",
      "through: 77, renner, hanks', widely, don't\n",
      "mr: tony, implicated, chaired, jack, ron\n",
      "leave: pay, apologise, blocking, letting, graphical\n",
      "5bn: 8bn, 16bn, purchased, 230, relationships\n",
      "met: sol, cautious, segment, rafa, jeff\n",
      "believed: splits, who, there, arrested, gartner\n",
      "debut: formula, hmv, hague, treasure, ranking\n",
      "images: lieutenant, 444, reaction, articles, cameras\n",
      "sound: averaged, casinos, attitude, ugly, zealand\n",
      "champions: premier, fixtures, football, nine, few\n",
      "individual: cautious, value, rebound, clinton, doubt\n",
      "businesses: medium, hmv, showbusiness, indebted, values\n",
      "deutsche: ecb, central, ds, ancestors, metatarsal\n",
      "especially: kuznetsova, honda, maserati, locking, seized\n",
      "machine: uk, rapid, mostly, wireless, prefer\n",
      "files: longer, doubt, lot, gb, confess\n",
      "positive: strengthen, rigorous, censorship, fifa, traditionally\n",
      "pop: homeland, novo, ambev, empty, judgement\n",
      "\n",
      "\n",
      "Epoch: 2/5 started\n",
      "2242/2242 [==============================] - 93s 42ms/step - loss: 0.0260\n",
      "election: attorney, forthcoming, empt, labour's, peaks\n",
      "months: weeks, years, greet, days, creativity\n",
      "with: honoured, entries, locking, g7, teething\n",
      "you: afford, we, know, don't, goodness\n",
      "were: are, where, say, want, wake\n",
      "win: outline, rebound, boxes, midway, blank\n",
      "those: stooge, need, people, nas, bravery\n",
      "music: cameras, mp3, media, beta, estimating\n",
      "also: which, be, confess, we, dyer\n",
      "around: dealt, lectures, commenting, hanks', effort\n",
      "best: supporting, asante, counterparts, actor, category\n",
      "him: ira, graphical, morquendi's, textures, retro\n",
      "too: so, how, larger, faster, less\n",
      "into: 'no, abused, accidentally, us, weren't\n",
      "through: hanks', renner, texting, dancing, made\n",
      "mr: tony, jack, implicated, article, insistence\n",
      "leave: pay, apologise, suited, graphical, locking\n",
      "5bn: 1bn, 8bn, 152m, 7bn, 34bn\n",
      "met: sol, euro's, submissions, 300bn, arrangement\n",
      "believed: lads, homeland, deprived, simpler, macklin\n",
      "debut: reference, toshack, hague, musicology, simonetti\n",
      "images: 444, 167, lieutenant, articles, keaveney\n",
      "sound: ugly, averaged, goldfine, casinos, upgraded\n",
      "champions: premier, fixtures, football, rugby, few\n",
      "individual: productions, famine, what's, assessing, euronext\n",
      "businesses: medium, contraction, pocket, handedly, apologise\n",
      "deutsche: central, ecb, austria, metatarsal, 2mbps\n",
      "especially: kuznetsova, maserati, thai, locking, fishing\n",
      "machine: uk, prefer, mostly, telephone, wireless\n",
      "files: punishments, mpaa, rousing, divides, michael's\n",
      "positive: strengthen, traditionally, censorship, means, pin\n",
      "pop: empty, buddy, depend, homeland, ambev\n",
      "\n",
      "\n",
      "Epoch: 3/5 started\n",
      "2241/2241 [==============================] - 93s 42ms/step - loss: 0.0160\n",
      "election: attorney, forthcoming, empt, labour's, outset\n",
      "months: weeks, years, rbs, creativity, days\n",
      "with: honoured, reservoir, teething, uphill, breach\n",
      "you: afford, they, we, goodness, don't\n",
      "were: are, where, say, when, because\n",
      "win: streamed, rebound, boxes, outline, blank\n",
      "those: people, stooge, nas, aadc, ahead\n",
      "music: cameras, mp3, divide, revolution, distribute\n",
      "also: be, which, dyer, remain, made\n",
      "around: dealt, lectures, commenting, effort, hanks'\n",
      "best: supporting, category, asante, actor, counterparts\n",
      "him: taken, graphical, climbing, me, retro\n",
      "too: so, how, pretty, happier, overly\n",
      "into: rigging, accidentally, fatal, 'no, bonus\n",
      "through: hanks', locking, considerable, doesn't, juninho\n",
      "mr: tony, implicated, ron, insistence, jack\n",
      "leave: pay, suited, locking, apologise, unsubstantiated\n",
      "5bn: 8bn, 1bn, 7bn, 152m, 3bn\n",
      "met: sol, submissions, euro's, 300bn, arrangement\n",
      "believed: homeland, immersive, frame, unconditional, deprived\n",
      "debut: hague, treasure, princes, reference, musicology\n",
      "images: 167, 444, lieutenant, keaveney, overtaking\n",
      "sound: illegitimate, ugly, casinos, eff, zen\n",
      "champions: premier, celtic, football, rugby, few\n",
      "individual: inexperienced, aviator, famine, thai, phoney\n",
      "businesses: medium, contraction, components, pocket, divisions\n",
      "deutsche: central, austria, austria's, metatarsal, donald\n",
      "especially: kuznetsova, analysys, thai, maserati, locking\n",
      "machine: values, enhance, uk, public, mostly\n",
      "files: unbiased, rousing, lunchtime, madness, episodes\n",
      "positive: means, traditionally, rigorous, strengthen, censorship\n",
      "pop: depend, 2009, empty, wars, homeland\n",
      "\n",
      "\n",
      "Epoch: 4/5 started\n",
      "2242/2242 [==============================] - 93s 41ms/step - loss: 0.0120\n",
      "election: attorney, forthcoming, labour's, faithful, bureau\n",
      "months: weeks, nations, years, staggering, rbs\n",
      "with: accession, honoured, icann, locking, uphill\n",
      "you: afford, we, they, goodness, disguise\n",
      "were: are, was, say, woefully, because\n",
      "win: streamed, outline, blank, boxes, regaining\n",
      "those: sits, wooing, people, stooge, ahead\n",
      "music: cameras, mp3, divide, subscriber, distribute\n",
      "also: be, which, made, remain, dyer\n",
      "around: moment, contents, immense, latest, fork\n",
      "best: supporting, asante, counterparts, actor, category\n",
      "him: me, climbing, apologise, trying, stella\n",
      "too: so, pretty, larger, overly, predictions\n",
      "into: thorough, rigging, accidentally, 'no, abused\n",
      "through: hanks', dodge, shareholder, locking, neighbouring\n",
      "mr: implicated, tony, 63, ron, bernie\n",
      "leave: pay, suited, need, locking, unsubstantiated\n",
      "5bn: 7bn, 8bn, 3bn, 2bn, 1bn\n",
      "met: sol, submissions, euro's, zeppelin's, 300bn\n",
      "believed: homeland, joked, dismisses, blogosphere, added\n",
      "debut: youngster, solo, formula, commercially, etzioni\n",
      "images: worked, lieutenant, 167, 444, healthy\n",
      "sound: illegitimate, ugly, dimension, casinos, roof\n",
      "champions: premier, celtic, football, piled, neighbour\n",
      "individual: attempt, average, extra, effort, forty\n",
      "businesses: medium, components, cadillac, soon, handedly\n",
      "deutsche: austria, austria's, central, donald, ecb\n",
      "especially: locking, healthcare, hare, petrochemicals, maserati\n",
      "machine: wireless, telephone, unforced, prefer, rapid\n",
      "files: participation, lunchtime, participant, unbiased, rousing\n",
      "positive: minutes, rigorous, rundown, pin, alcatel\n",
      "pop: wars, buddy, trek, 2009, semitism\n",
      "\n",
      "\n",
      "Epoch: 5/5 started\n",
      "2242/2242 [==============================] - 93s 41ms/step - loss: 0.0098\n",
      "election: attorney, posters, forthcoming, november's, month's\n",
      "months: weeks, years, nations, rbs, thirds\n",
      "with: reservoir, honoured, accession, confidentiality, souls\n",
      "you: afford, we, they, goodness, asked\n",
      "were: are, slashed, woefully, was, want\n",
      "win: streamed, outline, vauxhall, browse, hang\n",
      "those: vocal, sits, people, stooge, ahead\n",
      "music: cameras, mp3, hp's, refuseniks, divide\n",
      "also: which, denying, made, given, remain\n",
      "around: moment, decrease, misconception, polled, â£0\n",
      "best: supporting, category, asante, counterparts, actor\n",
      "him: need, preparing, ready, discuss, me\n",
      "too: fanfare, so, larger, happier, overly\n",
      "into: thorough, rigging, abused, accidentally, comprising\n",
      "through: hanks', stringent, ssl, verify, device\n",
      "mr: ron, tony, bernie, jack, 63\n",
      "leave: pay, need, unsubstantiated, suited, return\n",
      "5bn: 8bn, 2bn, 1bn, 3bn, 7bn\n",
      "met: talks, alastair, documentaries, euro's, rafa\n",
      "believed: locking, joked, frame, wanted, awol\n",
      "debut: solo, speakerboxxx, youngster, nasty, toshack\n",
      "images: 117, pattern, recorder, lennon, unexpectedly\n",
      "sound: illegitimate, ugly, indigenous, dimension, roof\n",
      "champions: premier, celtic, football, representatives, neighbour\n",
      "individual: extra, attempt, average, improvement, survived\n",
      "businesses: medium, sell, redder, abusive, handedly\n",
      "deutsche: central, austria's, donald, ecb, austria\n",
      "especially: asians, peugeot, taped, grandmother, petrochemicals\n",
      "machine: unforced, wireless, rapid, vehicle, workplace\n",
      "files: participation, granted, sunderland, lunchtime, unbiased\n",
      "positive: rigorous, tci's, rundown, beenie, alcatel\n",
      "pop: achieve, 2009, urban, pioneering, 2003\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glove_validation_callback = ValidationCallback(valid_term_ids, glove_model, tokenizer)\n",
    "\n",
    "# Train the model for several epochs\n",
    "for ei in range(epochs):\n",
    "    \n",
    "    print(\"Epoch: {}/{} started\".format(ei+1, epochs))\n",
    "    \n",
    "    news_glove_data_gen = glove_data_generator(\n",
    "        news_sequences, window_size, batch_size, n_vocab\n",
    "    )\n",
    "    \n",
    "    glove_model.fit(\n",
    "        news_glove_data_gen, epochs=1, \n",
    "        callbacks=glove_validation_callback,        \n",
    "    )\n",
    "\n",
    "    \n",
    "# Save the embeddings\n",
    "os.makedirs('glove_embeddings', exist_ok=True)\n",
    "\n",
    "np.save(\n",
    "    os.path.join(\"glove_embeddings\", \"context_embeddings.npy\"), \n",
    "    glove_model.get_layer(\"context_embedding\").get_weights()[0]\n",
    ")\n",
    "np.save(\n",
    "    os.path.join(\"glove_embeddings\", \"target_embeddings.npy\"), \n",
    "    glove_model.get_layer(\"target_embedding\").get_weights()[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Word Similarities \n",
    "We calculate the similarity between two given words in terms of the cosine distance. To do this efficiently we use matrix operations to do so, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
