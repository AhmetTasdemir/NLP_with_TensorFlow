{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6647d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pylab\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import lil_matrix\n",
    "import nltk # standard preprocessing\n",
    "import operator # sorting items in dictionary by value\n",
    "#nltk.download() #tokenizers/punkt/PY3/english.pickle\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6fbb9",
   "metadata": {},
   "source": [
    "## Understanding the data\n",
    "\n",
    "### Downloading the data\n",
    "\n",
    "This code downloads a [BBC dataset](hhttp://mlg.ucd.ie/files/datasets/bbc-fulltext.zip) consisting of news articles published by BBC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b1129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "bbc-fulltext.zip has already been extracted\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "\n",
    "\n",
    "def download_data(url, data_dir):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    \n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "  \n",
    "    if not os.path.exists(file_path):\n",
    "        print('Downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print(\"File already exists\")\n",
    "  \n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    if not os.path.exists(extract_path):\n",
    "        \n",
    "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "  \n",
    "    else:\n",
    "        print(\"bbc-fulltext.zip has already been extracted\")\n",
    "    \n",
    "download_data(url, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08272665",
   "metadata": {},
   "source": [
    "## Using pre-trained ELMo Model\n",
    "\n",
    "### Downloading the ELMo Model from TFHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7c5a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "elmo_layer = hub.KerasLayer(\"https://tfhub.dev/google/elmo/3\", signature=\"tokens\",signature_outputs_as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45986d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lstm_outputs2': <tf.Tensor: shape=(1, 6, 1024), dtype=float32, numpy=\n",
      "array([[[ 0.6206704 ,  0.36537755,  0.1887973 , ..., -0.84178007,\n",
      "          0.356871  ,  0.16665666],\n",
      "        [ 0.86018425, -0.7156644 ,  0.3361352 , ..., -0.02970919,\n",
      "          0.23038185,  1.8898063 ],\n",
      "        [-0.01657382, -0.6142872 ,  0.12097765, ..., -0.84056723,\n",
      "          1.2542009 ,  0.7461188 ],\n",
      "        [-0.7640561 , -0.46110973, -1.4737943 , ..., -1.6910062 ,\n",
      "          0.24993908, -0.01837131],\n",
      "        [-0.31592393, -0.5211221 , -0.6046509 , ..., -0.68753093,\n",
      "         -0.31786534,  0.02256058],\n",
      "        [ 0.46374235, -0.20050219, -0.61079466, ..., -0.03458577,\n",
      "          0.17038181,  0.70538455]]], dtype=float32)>, 'elmo': <tf.Tensor: shape=(1, 6, 1024), dtype=float32, numpy=\n",
      "array([[[ 0.30815446,  0.2663037 ,  0.23561308, ..., -0.37085718,\n",
      "          0.16490504, -0.07245933],\n",
      "        [ 0.5142877 , -0.13532332,  0.11090418, ...,  0.04046869,\n",
      "         -0.04789776,  0.73659605],\n",
      "        [-0.02588062, -0.07283628, -0.07935593, ..., -0.29072458,\n",
      "          0.72421384,  0.4386348 ],\n",
      "        [-0.3479806 , -0.02910245, -0.81993055, ..., -0.9204842 ,\n",
      "          0.0218881 ,  0.12105996],\n",
      "        [-0.21827474, -0.13076577, -0.252096  , ..., -0.29693633,\n",
      "         -0.15828086, -0.04900736],\n",
      "        [ 0.10072535, -0.02953451, -0.24494296, ..., -0.3723503 ,\n",
      "         -0.14875795,  0.21592236]]], dtype=float32)>, 'word_emb': <tf.Tensor: shape=(1, 6, 512), dtype=float32, numpy=\n",
      "array([[[-0.06904861,  0.11261537,  0.23713253, ...,  0.08062501,\n",
      "          0.09338927, -0.1899938 ],\n",
      "        [ 0.07608999,  0.5802494 ,  0.4205985 , ...,  0.28180832,\n",
      "         -0.62749267, -0.3938945 ],\n",
      "        [ 0.19154741,  0.22998688, -0.2894386 , ..., -0.0644654 ,\n",
      "          0.5810187 ,  0.21768005],\n",
      "        [ 0.04337819,  0.13920835, -0.41552824, ..., -0.3019298 ,\n",
      "          0.08007848,  0.10883449],\n",
      "        [-0.06904861,  0.11261537,  0.23713253, ...,  0.08062501,\n",
      "          0.09338927, -0.1899938 ],\n",
      "        [-0.22028118,  0.08463251,  0.13379273, ..., -0.95866007,\n",
      "         -0.94893765, -0.93102676]]], dtype=float32)>, 'sequence_len': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([6], dtype=int32)>, 'default': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[ 0.05517193, -0.02187644, -0.17496802, ..., -0.36848065,\n",
      "         0.0926784 ,  0.2317911 ]], dtype=float32)>, 'lstm_outputs1': <tf.Tensor: shape=(1, 6, 1024), dtype=float32, numpy=\n",
      "array([[[ 0.37284163,  0.32091814,  0.2809094 , ..., -0.35141647,\n",
      "          0.04445482, -0.19404082],\n",
      "        [ 0.60658896, -0.27055493, -0.42402118, ..., -0.13069308,\n",
      "          0.25341755,  0.71387637],\n",
      "        [-0.25261545,  0.16579145, -0.06960682, ...,  0.03285899,\n",
      "          0.33742195,  0.35210565],\n",
      "        [-0.32326382,  0.23459402, -0.57046914, ..., -0.7685164 ,\n",
      "         -0.26435328,  0.27271673],\n",
      "        [-0.26985168,  0.01620946, -0.38876963, ..., -0.283903  ,\n",
      "         -0.2503665 ,  0.02041115],\n",
      "        [ 0.05871491,  0.02726615, -0.25782692, ..., -0.12380506,\n",
      "          0.33228195,  0.8734092 ]]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokens_input = tf.constant(\n",
    "    [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"]    ]\n",
    ")\n",
    "\n",
    "tokens_length = tf.constant([6])\n",
    "\n",
    "\n",
    "res = elmo_layer({\n",
    "        \"tokens\": tokens_input,\n",
    "        \"sequence_len\": tokens_length\n",
    "    })\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b334292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
