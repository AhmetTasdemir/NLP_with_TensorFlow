{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66cf2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ea2c9",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "This code downloads a [BBC dataset](hhttp://mlg.ucd.ie/files/datasets/bbc-fulltext.zip) consisting of news articles published by BBC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a066561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "bbc-fulltext.zip has already been extracted\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "\n",
    "\n",
    "def download_data(url, data_dir):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    \n",
    "    # Create the data directory if not exist\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "    \n",
    "    # If file doesnt exist, download\n",
    "    if not os.path.exists(file_path):\n",
    "        print('Downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print(\"File already exists\")\n",
    "  \n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    \n",
    "    # If data has not been extracted already, extract data\n",
    "    if not os.path.exists(extract_path):        \n",
    "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "    else:\n",
    "        print(\"bbc-fulltext.zip has already been extracted\")\n",
    "    \n",
    "download_data(url, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544e94b",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Here we read all the files and keep them as a list of strings, where each string is a single article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7494c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 361.txt\n",
      "Detected 2225 stories\n",
      "865163 words found in the total news set\n",
      "Example words (start):  Windows worm travels with Tetris  Users are being \n",
      "Example words (end):  is years at Stradey as \"the best time of my life.\"\n"
     ]
    }
   ],
   "source": [
    "def read_data(data_dir):\n",
    "    \n",
    "    # This will contain the full list of stories\n",
    "    news_stories = []    \n",
    "    filenames = []\n",
    "    print(\"Reading files\")\n",
    "    \n",
    "    i = 0 # Just used for printing progress\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        \n",
    "        for fi, f in enumerate(files):\n",
    "            \n",
    "            # We don't read the readme file\n",
    "            if 'README' in f:\n",
    "                continue\n",
    "            \n",
    "            # Printing progress\n",
    "            i += 1\n",
    "            print(\".\"*i, f, end='\\r')\n",
    "            \n",
    "            # Open the file\n",
    "            with open(os.path.join(root, f), encoding='latin-1') as text_file:\n",
    "                \n",
    "                story = []\n",
    "                # Read all the lines\n",
    "                for row in text_file:\n",
    "                                        \n",
    "                    story.append(row.strip())\n",
    "                    \n",
    "                # Create a single string with all the rows in the doc\n",
    "                story = ' '.join(story)                        \n",
    "                # Add that to the list\n",
    "                news_stories.append(story)  \n",
    "                filenames.append(os.path.join(root, f))\n",
    "                \n",
    "        print('', end='\\r')\n",
    "        \n",
    "    print(\"\\nDetected {} stories\".format(len(news_stories)))\n",
    "    return news_stories, filenames\n",
    "                \n",
    "  \n",
    "news_stories, filenames = read_data(os.path.join('data', 'bbc'))\n",
    "\n",
    "# Printing some stats and sample data\n",
    "print('{} words found in the total news set'.format(sum([len(story.split(' ')) for story in news_stories])))\n",
    "print('Example words (start): ',news_stories[0][:50])\n",
    "print('Example words (end): ',news_stories[-1][-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12298545",
   "metadata": {},
   "source": [
    "## Build a Tokenizer\n",
    "\n",
    "Here we build a tokenizer, that performs simple preprocessing like,\n",
    "\n",
    "* Converting letters to lower case\n",
    "* Removing punctuation\n",
    "\n",
    "and tokenize the strings based on a defined separator. Then each token is converted to an Integer ID, as computers understand numbers, not strings. In the background, the tokenizer builds a word to index dictionary, that defines a unique ID for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3405d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fitted on the tokenizer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "n_vocab = 15000 + 1\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=n_vocab - 1,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', oov_token=''\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(news_stories)\n",
    "print(\"Data fitted on the tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6cc22a",
   "metadata": {},
   "source": [
    "## Generate labels for data\n",
    "\n",
    "We generate a label using the filenames to train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43c25400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data/bbc/tech/272.txt    4\n",
       "data/bbc/tech/127.txt    4\n",
       "data/bbc/tech/370.txt    4\n",
       "data/bbc/tech/329.txt    4\n",
       "data/bbc/tech/240.txt    4\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ser = pd.Series(filenames, index=filenames).str.split(os.path.sep, expand=True).iloc[:, -2].map(\n",
    "    {'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}\n",
    ")\n",
    "labels_ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec0dcc",
   "metadata": {},
   "source": [
    "## Create train/test split\n",
    "\n",
    "Here we use 67% data as training and 33% as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1876e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_labels, test_labels = train_test_split(labels_ser, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457b5d1",
   "metadata": {},
   "source": [
    "## Generating document embeddings\n",
    "\n",
    "Here we write a function to generate document embeddings from the previous embedding arrays we saved to the disk for `skip-gram`, `CBOW` and `GloVe` algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c0967e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_document_embeddings(texts, filenames, tokenizer, embeddings):\n",
    "    \n",
    "    \"\"\" This function takes a sequence of tokens and compute the mean embedding vector \\\n",
    "    from the word vectors of all the tokens in the document \"\"\"\n",
    "    \n",
    "    doc_embedding_df = [] # Contains document embeddings for all the articles\n",
    "    assert isinstance(embeddings, pd.DataFrame), 'embeddings must be a pd.DataFrame'\n",
    "    \n",
    "    # This is a trick we use to quickly get the text preprocessed by the tokenizer\n",
    "    # We first convert text to a sequences, and then back to text, which will give the\n",
    "    # preprocessed tokens\n",
    "    sequences = tokenizer.texts_to_sequences(texts)    \n",
    "    preprocessed_texts = tokenizer.sequences_to_texts(sequences)\n",
    "    \n",
    "    # For each text,\n",
    "    for text in preprocessed_texts:\n",
    "        # Make sure we had matches for tokens in the embedding matrx\n",
    "        assert embeddings.loc[text.split(' '), :].shape[0]>0\n",
    "        # Compute mean of all the embeddings associated with words\n",
    "        mean_embedding = embeddings.loc[text.split(' '), :].mean(axis=0)\n",
    "        # Add that to list\n",
    "        doc_embedding_df.append(mean_embedding)\n",
    "        \n",
    "    # Save the doc embeddings in a dataframe\n",
    "    doc_embedding_df = pd.DataFrame(doc_embedding_df, index=filenames)\n",
    "    \n",
    "    return doc_embedding_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088f799",
   "metadata": {},
   "source": [
    "## Compute skip-gram based document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Load the skip-gram embeddings context and target\n",
    "skipgram_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('../Ch03-Word-Vectors/skipgram_embeddings', 'context_embedding.pkl')\n",
    ")\n",
    "skipgram_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('../Ch03-Word-Vectors/skipgram_embeddings', 'target_embedding.pkl')\n",
    ")\n",
    "\n",
    "# Compute the mean of context & target embeddings for better embeddings\n",
    "skipgram_embeddings = (skipgram_context_embeddings + skipgram_target_embeddings)/2\n",
    "# Generate the document embeddings with the average context target embeddings\n",
    "skipgram_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, skipgram_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29543a4",
   "metadata": {},
   "source": [
    "## Train a document classifier\n",
    "\n",
    "Here we train a simple document classifier, using document embeddings as inputs and labels we generated as targets. To get a consistent measure, we will run several trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25b3ba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9319727891156463, 0.9292517006802721, 0.9374149659863945, 0.9360544217687075, 0.9346938775510204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_classification_accuracy(doc_embeddings, train_labels, test_labels, n_trials):\n",
    "    \"\"\" Train a simple MLP model for several trials and measure test accuracy\"\"\"\n",
    "    \n",
    "    accuracies = [] # Store accuracies across trials\n",
    "    \n",
    "    # For each trial\n",
    "    for trial in range(n_trials):\n",
    "        # Create a MLP classifier\n",
    "        mlp_classifier = MLPClassifier()\n",
    "        \n",
    "        # Fit the model on training data\n",
    "        mlp_classifier.fit(doc_embeddings.loc[train_labels.index], train_labels)\n",
    "        \n",
    "        # Get the predictions for test data\n",
    "        predictions = mlp_classifier.predict(doc_embeddings.loc[test_labels.index])\n",
    "    \n",
    "        # Compute accuracy\n",
    "        accuracies.append(accuracy_score(predictions, test_labels))\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Get classification accuracy for skip-gram models\n",
    "skipgram_accuracies = get_classification_accuracy(\n",
    "    skipgram_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "\n",
    "print(\"Skip-gram accuracies: {}\".format(skipgram_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aec63b",
   "metadata": {},
   "source": [
    "## Train a classifier on CBOW based document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1eeb9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('../Ch03-Word-Vectors/cbow_embeddings', 'context_embedding.pkl')\n",
    ")\n",
    "cbow_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('../Ch03-Word-Vectors/cbow_embeddings', 'target_embedding.pkl')\n",
    ")\n",
    "\n",
    "cbow_embeddings = (cbow_context_embeddings + cbow_target_embeddings)/2\n",
    "cbow_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, cbow_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf065086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9360544217687075, 0.9292517006802721, 0.9319727891156463, 0.9346938775510204, 0.9333333333333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "cbow_accuracies = get_classification_accuracy(\n",
    "    cbow_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(cbow_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14000a4d",
   "metadata": {},
   "source": [
    "## Train a classifier on GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e383884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_context_embeddings = pd.read_pickle(\n",
    "    os.path.join('glove_embeddings', 'context_embedding_and_bias.pkl')\n",
    ")\n",
    "glove_target_embeddings = pd.read_pickle(\n",
    "    os.path.join('glove_embeddings', 'target_embedding_and_bias.pkl')\n",
    ")\n",
    "\n",
    "glove_embeddings = (glove_context_embeddings.iloc[:, :-1] + glove_target_embeddings.iloc[:, :-1])/2\n",
    "glove_doc_embeddings = generate_document_embeddings(news_stories, filenames, tokenizer, glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "584e58b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8136054421768707, 0.8081632653061225, 0.819047619047619, 0.8149659863945579, 0.8095238095238095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thushv89/anaconda3/envs/packt.nlp.tf2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "glove_accuracies = get_classification_accuracy(\n",
    "    glove_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(glove_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f8174",
   "metadata": {},
   "source": [
    "## Train a classifier on ELMo document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1973783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_doc_embeddings = pd.read_pickle(\n",
    "    os.path.join('elmo_embeddings', 'elmo_embeddings.pkl')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e02751f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9823129251700681, 0.9850340136054422, 0.9823129251700681, 0.9809523809523809, 0.9782312925170068]\n"
     ]
    }
   ],
   "source": [
    "elmo_accuracies = get_classification_accuracy(\n",
    "    elmo_doc_embeddings, train_labels, test_labels, n_trials=5\n",
    ")\n",
    "print(elmo_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06df915",
   "metadata": {},
   "source": [
    "## Plot the accuracies of different models\n",
    "\n",
    "Here we plot the accuracies from 5 trials, for different algorithms as box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c3f2383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skipgram</th>\n",
       "      <th>CBOW</th>\n",
       "      <th>GloVe</th>\n",
       "      <th>ELMo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.931973</td>\n",
       "      <td>0.936054</td>\n",
       "      <td>0.813605</td>\n",
       "      <td>0.982313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.929252</td>\n",
       "      <td>0.929252</td>\n",
       "      <td>0.808163</td>\n",
       "      <td>0.985034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.937415</td>\n",
       "      <td>0.931973</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.982313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.936054</td>\n",
       "      <td>0.934694</td>\n",
       "      <td>0.814966</td>\n",
       "      <td>0.980952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.934694</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.978231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Skipgram      CBOW     GloVe      ELMo\n",
       "0  0.931973  0.936054  0.813605  0.982313\n",
       "1  0.929252  0.929252  0.808163  0.985034\n",
       "2  0.937415  0.931973  0.819048  0.982313\n",
       "3  0.936054  0.934694  0.814966  0.980952\n",
       "4  0.934694  0.933333  0.809524  0.978231"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame(\n",
    "    np.array([skipgram_accuracies, cbow_accuracies, glove_accuracies, elmo_accuracies]).T,\n",
    "    columns = ['Skipgram', 'CBOW', \"GloVe\", \"ELMo\"]\n",
    ")\n",
    "\n",
    "accuracy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6499c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot = accuracy_df.boxplot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8a1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
